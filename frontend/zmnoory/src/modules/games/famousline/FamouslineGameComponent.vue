<template>
  <div class="webrtc-container">
    <!-- ì˜¤ë²„ë ˆì´ UI ì˜ì—­ -->
    <div class="ui-overlay">
      <div class="top-bar">
        <span class="info-text">ğŸ¬ ëª…ëŒ€ì‚¬ ë”°ë¼í•˜ê¸°</span>
        <span class="timer">{{ ref_formattedTime }}</span>
      </div>
      <div class="button-bar">
        <button v-if="ref_isGameStart" @click="onStart">ê²Œì„ ì‹œì‘</button>
        <button v-if="ref_isStopRecord" @click="onStop">ì¤‘ì§€</button> 
      </div>
      
      <!-- ìŒëŸ‰ ë ˆë²¨ë°” ì»¨í…Œì´ë„ˆ -->
      <div v-if ="ref_isVolumebar" class="bars-container">
        <div
          v-for="(bar, i) in bars"
          :key="i"
          class="bar"
          :style="{ height: bar + '%' }"
        ></div>
      </div>

      <div v-if="ref_isVolumebar"  class="level-meter">
        <div class="level-fill" :style="{ width: (levelPct * 100).toFixed(0) + '%' }"></div>
      </div>
      <div class="speaking-indicator" :class="{ on: isSpeaking }">
        {{ isSpeaking ? 'ğŸ¤ Speaking' : 'â€¦' }}
      </div>

    <div v-show="ref_isVolumebar">
      <img
        v-show="!ref_isSpeaking"
        src="/anim/popcat_pause.png"
        class="talk-gif"
      />
      <img
        v-show="ref_isSpeaking"
        :src="ref_gifSrc"
        class="talk-gif"
      />
    </div>
    </div>

    
    <!-- WebRTC ë¹„ë””ì˜¤ -->
    <video ref="ref_video" autoplay playsinline muted class="webrtc-video"></video>
    <!-- ë Œë”ë§ ìº”ë²„ìŠ¤ -->
    <canvas ref="ref_maincanvas" class="overlay-canvas"></canvas>


     <!-- ì „ì²´ íŒŒí˜• ë¯¸ë‹ˆë§µ -->
    <canvas v-show = "ref_isShowOverview" ref="ref_overviewWave" class="ref-overview" :class="{ 'fade-in': ref_overviewVisible }"></canvas>
    <!-- ì›ë³¸ ëŒ€ì‚¬ ìŒì„± ì‹¤ì‹œê°„ íŒŒí˜• ìº”ë²„ìŠ¤ -->
    <canvas  v-show = "!ref_isShowOverview" ref="ref_refWave" class="ref-wave"   :class="{ 'is-morphing': ref_isMorphing }"></canvas>


      <!-- ì›ë³¸ ëŒ€ì‚¬ ì˜ìƒ ì˜¤ë²„ë ˆì´ -->
    <div v-if="ref_isShowClip" class="refclip-overlay">
      <img
        src = "/clips/thumbnail_takeEverything.png"
        class = "refclip-img"
        ></img>


      <video
        ref="ref_refClip"
        :src="Info_VideoClips[0].src"
        class="refclip-video"
        playsinline
        controls
      ></video>
    </div>

    <!-- (ì„ íƒ) ë”°ë¼í•˜ê¸° ì¹´ìš´íŠ¸ë‹¤ìš´ í‘œì‹œ -->
    <div v-if="ref_countdown" class="countdown-overlay">
      {{ ref_countdown }}
    </div>

    <!-- í”Œë ˆì´ê°€ ë…¹í™”ëœ ì˜ìƒ -->
    <video v-if="ref_recordedVideoURL" :src="ref_recordedVideoURL" class="recorded-preview" 
    controls autoplay loop></video>
  </div>


    <audio v-if="ref_recordedAudioURL" :src="ref_recordedAudioURL" class = "recorded-preview" 
     preload="auto"></audio>
     
    <!-- í•„ìš” ì‹œ ë‹¤ìš´ë¡œë“œ -->
    <a :href="ref_recordedAudioURL!" class="download-link"  download="player.webm">íŒŒì¼ ì €ì¥</a>

</template>

<script setup lang="ts">
import { ref, onMounted, onBeforeUnmount, nextTick  } from 'vue'
import { MediaUtils } from './class/MediaUtils'
import type { VideoClipInfo } from './types/FamouslineTypes'
import type { ImagePayload } from '@/services/info';
// import type { ImagePayload } from '@/services/info';

// emit ê°ì²´ë“¤
const emit_Result = defineEmits<{
  (e:'emit_gameResult' , value : string) : void
  (e:'emit_s3url', value:string) : void
  (e:'emit_video', value:string):void
  (e:'emit_cropImages', value:ImagePayload[]):void
  (e:'emit_videoBlob', value:Blob):void
}>()

const props = defineProps<{
  isTest: boolean
}>()


const gifBase = '/anim/popcat.gif'
const ref_formattedTime = ref('00:00')

let stream : MediaStream | null = null;
let mediaRecorder : MediaRecorder | null = null;


/** íŒŒí˜• ì €ì¥ì†Œ: í™”ë©´ í­(í”½ì…€)ê³¼ 1:1ë¡œ ë§¤í•‘ëœ ì§„í­ê°’(0..1) */
let waveStore: Float32Array | null = null


/** ê°œìš” íŒŒí˜• ë Œë”ë§ìš© ì»¨í…ìŠ¤íŠ¸/ì¹˜ìˆ˜ */
let octx: CanvasRenderingContext2D | null = null
let O_W = 0, O_H = 0, O_cols = 0

/** ë©”íƒ€ì •ë³´ */
let clipDuration = 0

// âœ… í”Œë ˆì´ì–´(ì‚¬ìš©ì) ì˜¤ë²„ë ˆì´ íŒŒí˜• ì €ì¥/íƒ€ì´ë°
let playerStore: Float32Array | null = null
let playerStartMs = 0
let playerTotalSec = 0


let ac: AudioContext | null = null
let micStream: MediaStream | null = null
let dest :MediaStreamAudioDestinationNode | null = null
let micRecorder : MediaRecorder | null = null
let micChunks: BlobPart[] = []

let src: MediaElementAudioSourceNode | null = null
let an: AnalyserNode | null = null
let rafId2: number | null = null

let audioCtx: AudioContext | null = null
let analyser: AnalyserNode | null = null
let sourceNode: MediaStreamAudioSourceNode | null = null
let rafId: number | null = null

let playerBlob: Blob[] | null = []

const Info_VideoClips : VideoClipInfo[] = [
  {
      src: '/clips/clip_takeEverything.mp4',
      line: 'ê¼­ ê·¸ë ‡ê²Œ ë‹¤ ê°€ì ¸ê°€ì•¼ë§Œ ì†ì´ í›„ë ¨í–ˆëƒ!'
  }
]

// Hysteresis ê¸°ë°˜ VAD(ë§í•˜ê¸° ê°ì§€) íŒŒë¼ë¯¸í„°
const THRESHOLD_ON  = 4  // ë§í•˜ê¸° ì‹œì‘ ì„ê³„ì¹˜ (ì •ê·œí™”)


//ref ê°ì²´ë“¤
const ref_video = ref<HTMLVideoElement | null>(null)
const ref_maincanvas = ref<HTMLCanvasElement | null>(null)
const ref_recordedVideoURL = ref<string | null>(null)
const ref_recordVideoBlob = ref<Blob | null>(null)
const ref_refClip = ref<HTMLVideoElement | null>(null)
const ref_isShowClip = ref<boolean>(false)
const ref_countdown = ref<number | null>(0)

/**
 * ê²Œì„ ì¤‘ ìŒëŸ‰ë°”ë¥¼ í‘œì‹œí•  ì§€ ì—¬ë¶€
 */
const ref_isVolumebar = ref<boolean>(false) 

/**
 * ê²Œì„ ì¤‘ ë…¹ìŒì„ ì¤‘ë‹¨í• ì§€ì— ëŒ€í•œ ì—¬ë¶€
 */
const ref_isStopRecord = ref<boolean>(false)

/** 
ê²Œì„ ì‹œì‘ ì—¬ë¶€ë¥¼ íŒë‹¨í•˜ëŠ” ë³€ìˆ˜
*/
const ref_isGameStart = ref<boolean>(true)


const ref_overviewWave = ref<HTMLCanvasElement|null>(null)

const ref_isShowOverview = ref<boolean>(false)

const ref_overviewVisible = ref(false) // ì „ì²´ íŒŒí˜•ì´ í™”ë©´ì— ìì—°ìŠ¤ëŸ½ê²Œ ë“œëŸ¬ë‚˜ëŠ” íƒ€ì´ë° ì œì–´ìš©

const ref_isMorphing = ref(false)

const ref_gifSrc = ref(gifBase)

const ref_isSpeaking = ref(false);

const ref_showPlayerOverlay = ref(false)   // âœ… í”Œë ˆì´ì–´ íŒŒí˜• 

const ref_recordedAudioURL = ref<string | null>(null);

// ë ˆë²¨/ë§í•˜ê¸° ìƒíƒœ
const levelPct = ref(0)     // 0.0 ~ 1.0

const isSpeaking = ref(false)

const bars = ref<number[]>(Array(10).fill(10)) // ì´ˆê¸° ë†’ì´ 10%

const ref_refWave  = ref<HTMLCanvasElement|null>(null)

onMounted(async () => {
  console.log(props.isTest ? "í…ŒìŠ¤íŠ¸ ëª¨ë“œ" : "ì‹¤ì œ ëª¨ë“œ");
  try {
    stream = await MediaUtils.getUserMediastream({
      video: true,
      audio: true, // ì´í›„ ìŒì„± ë…¹ìŒìš©
    }, ref_video.value);

    console.log('ì‚¬ìš©ì ì¹´ë©”ë¼ í™œì„±í™” ì™„ë£Œ');
  } catch (err) {
    console.error('âŒ ì¹´ë©”ë¼ ì ‘ê·¼ ì‹¤íŒ¨:', err);
    alert('ì¹´ë©”ë¼ ë˜ëŠ” ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.');
  }
});
;

async function onStart(){
    ref_isShowClip.value = true;
    ref_isGameStart.value = false;
    await nextTick();

    //Clipì¬ìƒ
    await startReferenceWave();
    await MediaUtils.playVideoStream(ref_refClip.value, false);
    MediaUtils.stopVideoStream(ref_refClip, async () => {
      console.log("í´ë¦½ ì¬ìƒ ì¤‘ì§€");
      ref_isShowClip.value = false;

      await nextTick();
      morphWaveToOverview(700) // ì›í•˜ëŠ” ì†ë„ë¡œ (ms)
      
      // ref_isShowOverview.value = true;
      //stopReferenceWave();
      startCountdown();
      
    });

    console.log("ë…¹í™” ì‹œì‘")
}

async function onStop(){
  if (RecordInterval) {
    clearInterval(RecordInterval);
    RecordInterval = null;
  }
  stopBarsMeter();
  await MediaUtils.finishRecord(mediaRecorder!);
  MediaUtils.connectBase64URL(ref_recordedVideoURL, ref_recordVideoBlob);

  drawOverviewAll(playerTotalSec)
}

//ë¦¬ì…‹í•¨ìˆ˜
// function resetWaveComparison() {
//   playerStore = null
//   playerTotalSec = 0
//   ref_showPlayerOverlay.value = false
//   drawOverviewAll(0) // ì›ë³¸ë§Œ í‘œì‹œ
// }

function startCountdown(second : number = 3){
  ref_countdown.value = second;
    console.log("ì¹´ìš´íŠ¸ë‹¤ìš´ ì‹œì‘:", ref_countdown.value);
  const interval = setInterval(() => {
    // console.log("ì¹´ìš´íŠ¸ë‹¤ìš´:", ref_countdown.value);
    ref_countdown.value! -=1;
    if(ref_countdown.value! <= 0){
      clearInterval(interval);
      RecordingPlayerLine();
    }
  }, 1000);

}

// ë²„íŠ¼ í´ë¦­ ì‹œ(=ì‚¬ìš©ì ì œìŠ¤ì²˜) ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ resume í•„ìš”
async function ensureAudioCtx() {
  if (!audioCtx) {
    audioCtx = new AudioContext()
  }
  if (audioCtx.state === 'suspended') {
    try { await audioCtx.resume() } catch {}
  }
}


async function startReferenceWave() {
  await nextTick()        
  const clip = ref_refClip.value
  const cvs  = ref_refWave.value
  const ocvs = ref_overviewWave.value
  if (!clip || !cvs || !ocvs) { console.warn('clip/canvas ì—†ìŒ'); return }

    // ë©”íƒ€(ì´ ê¸¸ì´) ì¤€ë¹„
  if (isNaN(clip.duration) || !clip.duration) {
    console.log("ì—¥ ì™œ ë“€ë ˆì´ì…˜ì´ ì•ˆì°í˜€")
    await new Promise<void>(res => {
      const h = () => { clip.removeEventListener('loadedmetadata', h); res() }
      clip.addEventListener('loadedmetadata', h, { once: true })
    })
  }
  clipDuration = clip.duration || 0
  console.log("ì´ì œ êµ¬í–‡ëƒ ? ",clipDuration)
  setupOverviewCanvas();

  if (!ac) ac = new AudioContext()
  if (ac.state === 'suspended') await ac.resume()

  if (!src) src = ac.createMediaElementSource(clip)
  an = ac.createAnalyser()
  an.fftSize = 2048                 // ì‹œê°„í•´ìƒë„â†‘
  an.smoothingTimeConstant = 0.7

  // ë¹„ë””ì˜¤ ìì²´ ì†Œë¦¬ëŠ” ìŒì†Œê±°í•˜ê³ , ì˜¤ë””ì˜¤ì»¨í…ìŠ¤íŠ¸ë¡œ ì¬ìƒ(ì¤‘ë³µ ë°©ì§€)
  // clip.muted = true
  clip.volume = 1
  src.connect(an)
  src.connect(ac.destination)

  const dpr = window.devicePixelRatio || 1
  const W = (cvs.clientWidth  || 600) * dpr
  const H = (cvs.clientHeight || 96)  * dpr
  cvs.width = W; cvs.height = H
  const g = cvs.getContext('2d')!

  const midY = Math.floor(H/2)
  const td = new Uint8Array(an.fftSize) // time-domain

  // ìƒ‰ìƒ(ë¶„í™ ì±„ìš°ê¸° + ë°”ë‹¥ ìª½ ë¶‰ì€ ê²½ê³„ ëŠë‚Œ)
  const fillGrad = g.createLinearGradient(0, 0, 0, H)
  fillGrad.addColorStop(0.00, '#ff33cc')
  fillGrad.addColorStop(0.60, '#ff00aa')
  fillGrad.addColorStop(1.00, '#7a005a')

  const edgeColor = '#ff2747' // ì•„ë˜ìª½ ì–‡ì€ ë¶‰ì€ ë¼ì¸ ëŠë‚Œ

  // ì¹¼ëŸ¼(ì„¸ë¡œì¤„) í­ê³¼ ìŠ¤í¬ë¡¤ ì†ë„
  const COL = Math.max(1, Math.round(2*dpr)) // ì„¸ë¡œ 2px ì •ë„
  const SPEED = COL                           // í”„ë ˆì„ë‹¹ ì˜¤ë¥¸ìª½ì— 1ì¹¼ëŸ¼ ì¶”ê°€

  const draw = () => {
    if (!an) return
    an.getByteTimeDomainData(td)

    // ê¸°ì¡´ ê·¸ë¦¼ì„ ì™¼ìª½ìœ¼ë¡œ ìŠ¤í¬ë¡¤
    const snap = g.getImageData(SPEED, 0, W - SPEED, H)
    g.putImageData(snap, 0, 0)
    g.clearRect(W - SPEED, 0, SPEED, H)

    // í•œ í”„ë ˆì„ì˜ í”¼í¬ ì§„í­ ê³„ì‚°(=overview ì¶•ì ì—ë„ ì‚¬ìš©)
    const samplesPerCol = Math.floor(td.length / 64) || 1
    let minV =  1, maxV = -1
    for (let i=0; i<samplesPerCol; i++) {
      const v = (td[i] - 128) / 128 // -1..1
      if (v < minV) minV = v
      if (v > maxV) maxV = v
    }
    // ì§„í­ì„ ìº”ë²„ìŠ¤ ë†’ì´ë¡œ ë§¤í•‘(ì‚´ì§ ê³¼ì¥)
    const amp = (Math.max(Math.abs(minV), Math.abs(maxV)) * 0.9)

    // ì‹¤ì‹œê°„ ì¹¼ëŸ¼ ê·¸ë¦¬ê¸°    
    const h   = Math.max(2*dpr, amp * (H/2))
    g.fillStyle = fillGrad
    g.fillRect(W - COL, midY - h, COL, h*2)

    // ì•„ë˜ìª½ ê°€ì¥ìë¦¬ ë¶‰ì€ ì–‡ì€ ë¼ì¸(ì›í•˜ì‹œë©´ ì£¼ì„ í•´ì œ)
    g.fillStyle = edgeColor
    g.fillRect(W - COL, midY + h - Math.max(1, Math.round(1*dpr)), COL, Math.max(1, Math.round(1*dpr)))

    accumulateOverview(amp, clip)
      // drawOverview(clip.currentTime)
      drawOverviewAll(clip.currentTime)

    rafId2 = requestAnimationFrame(draw)
  }
  draw()
}


async function startMicRecord() {
  if (!ac) ac = new AudioContext()
  micStream = await navigator.mediaDevices.getUserMedia({
    audio: { echoCancellation: true, noiseSuppression: true, autoGainControl: false }
  })
  const src = ac.createMediaStreamSource(micStream)
  const gain = ac.createGain()
  gain.gain.value = 1.0 // UIë¡œ ì¡°ì ˆ ê°€ëŠ¥

  dest = ac.createMediaStreamDestination()
  src.connect(gain)
  gain.connect(dest)

  micChunks = []
  // ë¸Œë¼ìš°ì € ì§€ì› ì½”ë±: audio/webm;codecs=opus ê°€ ê°€ì¥ í˜¸í™˜ ì¢‹ìŒ
  micRecorder = new MediaRecorder(dest.stream, { mimeType: 'audio/webm;codecs=opus' })
  micRecorder.ondataavailable = (e) => { if (e.data?.size) micChunks.push(e.data) }
  micRecorder.start()
}


function stopReferenceWave() {
  if (rafId2) cancelAnimationFrame(rafId2), rafId2=null
  try { src && src.disconnect() } catch {}
  try { an  && an.disconnect() } catch {}
  an = null
  // acëŠ” ë‹¤ë¥¸ ë¶„ì„ì— ì¬ì‚¬ìš© ê°€ëŠ¥. í•„ìš”í•˜ë©´ ac?.close()
}


async function stopMicRecord(): Promise<Blob> {
  if (!micRecorder) throw new Error('not recording')
  const done = new Promise<Blob>((resolve) => {
    micRecorder!.onstop = () => resolve(new Blob(micChunks, { type: 'audio/webm' }))
  })
  micRecorder.stop()

  
  return await done
}


async function startBarsMeter(stream: MediaStream) {
  ref_isVolumebar.value =true;
  sourceNode = audioCtx!.createMediaStreamSource(stream)
  analyser = audioCtx!.createAnalyser()
  analyser.fftSize = 256
  sourceNode.connect(analyser)

  const bufferLength = analyser.frequencyBinCount
  const dataArray = new Uint8Array(bufferLength)

  const draw = () => {
    if (!analyser) return

    analyser.getByteFrequencyData(dataArray)

    // ì „ì²´ ì£¼íŒŒìˆ˜ëŒ€ì—­ì„ ë§‰ëŒ€ ê°œìˆ˜ë¡œ ë¶„í• 
    const chunkSize = Math.floor(bufferLength / bars.value.length)
    bars.value = bars.value.map((_, idx) => {
      const start = idx * chunkSize
      const end = start + chunkSize
      const slice = dataArray.slice(start, end)
      const avg = slice.reduce((a, b) => a + b, 0) / slice.length
      return Math.min(100, (avg / 255) * 100) // % ê°’
    })

    analyser.smoothingTimeConstant = 0.8
    analyser.fftSize = 2048
    const timeData = new Uint8Array(analyser.fftSize);
    analyser.getByteTimeDomainData(timeData);
    let sum = 0
    for (let i = 0; i < timeData.length; i++) {
      const v = (timeData[i] - 128) / 128     // -1 ~ +1 ë¡œ ì •ê·œí™”
      sum += v * v
    }
    const rms = Math.sqrt(sum / timeData.length) // 0~1
    const levelPct = Math.min(1, rms * 1.4)      // ë³´ê¸° ì¢‹ê²Œ ìŠ¤ì¼€ì¼ ì¡°ì •
    const level100 = Math.round(levelPct * 100)  // 0~100 ë²”ìœ„ ì •ìˆ˜

    if(level100 >= THRESHOLD_ON){
      // console.log("speak!", level100);
      ref_isSpeaking.value = true;
    }
    else{
      ref_isSpeaking.value =false
    }
    
    accumulatePlayerOverlay(rms);
    rafId = requestAnimationFrame(draw)
  }
  draw()
}

function stopBarsMeter() {
  if (rafId) cancelAnimationFrame(rafId)
  try { sourceNode?.disconnect() } catch {}
  try { analyser?.disconnect() } catch {}
  sourceNode = null
  analyser = null
  audioCtx?.close()
  audioCtx = null
  ref_isVolumebar.value = false
}

let RecordInterval : NodeJS.Timeout | null = null

async function RecordingPlayerLine(){
  console.log("ë…¹í™” ì‹œì‘")
  mediaRecorder = MediaUtils.startRecord(stream!, ref_recordVideoBlob);
  ref_isStopRecord.value = true;

  console.log("ë…¹í™” ì‹œì‘ :",ref_refClip.value)
  let totaltime= Math.round(clipDuration+0.5);
  
  // âœ… ì˜¤ë²„ë ˆì´ ì´ˆê¸°í™”
  initPlayerOverlay(totaltime)

  await ensureAudioCtx();
  await startMicRecord();
  await startBarsMeter(stream!);
  RecordInterval = setInterval(async () => {
    ref_formattedTime.value = "00:" + String(totaltime).padStart(2, "0");
    totaltime--;

    if (totaltime < 0 && mediaRecorder && mediaRecorder.state !== "inactive") {
      // stopLevelMeter()
      stopBarsMeter();
      await MediaUtils.finishRecord(mediaRecorder!);
      MediaUtils.connectBase64URL(ref_recordedVideoURL, ref_recordVideoBlob);
      clearInterval(RecordInterval!);
      console.log(" ë…¹í™” ì¢…ë£Œ");

      // ë…¹ìŒ ëë‚œ ì§í›„
      const recordBlob = await stopMicRecord();
      playerBlob?.push(recordBlob);

      const url = URL.createObjectURL(recordBlob);
      console.log("url : ,", url)
      ref_recordedAudioURL.value = url;
      emit_Result('emit_video', ref_recordedVideoURL.value!);
      emit_Result('emit_s3url', "");
      emit_Result('emit_gameResult', 'success');
      emit_Result('emit_cropImages', []); // ì´ë¯¸ì§€ í¬ë¡­ì€ í˜„ì¬ ì‚¬ìš© ì•ˆí•¨
      emit_Result('emit_videoBlob', ref_recordVideoBlob.value!);
      
    }
  },1000);


}

function setupOverviewCanvas() {
  const cvs = ref_overviewWave.value
  if (!cvs) return
  const dpr = window.devicePixelRatio || 1
  const cssW = Math.max(300, cvs.clientWidth || 600)
  const cssH = Math.max(40,  cvs.clientHeight || 72)

  O_W = Math.round(cssW * dpr)
  O_H = Math.round(cssH * dpr)
  O_cols = O_W  // â€œí•œ í”½ì…€ = í•œ ì¹¼ëŸ¼â€ ì „ëµ

  cvs.width  = O_W
  cvs.height = O_H
  octx = cvs.getContext('2d')

  // ê¸°ì¡´ ë°ì´í„°ë¥¼ ìƒˆ í­ìœ¼ë¡œ ë¦¬ìƒ˜í”Œ(ì—†ìœ¼ë©´ ì‹ ê·œ)
  if (!waveStore) {
    waveStore = new Float32Array(O_cols)
  } 
  else if (waveStore.length !== O_cols) {
    const old = waveStore
    const next = new Float32Array(O_cols)
    for (let x = 0; x < O_cols; x++) {
      const t = x / (O_cols - 1)
      const ox = t * (old.length - 1)
      const i0 = Math.floor(ox)
      const i1 = Math.min(old.length - 1, i0 + 1)
      const a = ox - i0
      next[x] = old[i0] * (1 - a) + old[i1] * a
    }
    waveStore = next
  }
  // drawOverview(0) // ì´ˆê¸°í™”
  drawOverviewAll(0);
}

// function resampleArray(src: Float32Array, newLen: number) {
//   const out = new Float32Array(newLen)
//   for (let x=0; x<newLen; x++){
//     const t = x/(newLen-1)
//     const ox = t*(src.length-1)
//     const i0 = Math.floor(ox), i1 = Math.min(src.length-1, i0+1)
//     const a = ox - i0
//     out[x] = src[i0]*(1-a) + src[i1]*a
//   }
//   return out
// }


function accumulateOverview(amp: number, clip: HTMLVideoElement) {
  if (!waveStore || !O_cols || !clipDuration) return
  const t = clip.currentTime / clipDuration
  const x = Math.max(0, Math.min(O_cols - 1, Math.floor(t * (O_cols - 1))))
  // ê³¼ê±°ì— ê¸°ë¡ëœ ê°’ë³´ë‹¤ í¬ë©´ ê°±ì‹ (í”¼í¬ í™€ë“œ)
  waveStore[x] = Math.max(waveStore[x], Math.max(0, Math.min(1, amp)))
}

// function drawOverview(currentTimeSec: number) {
//   if (!octx || !waveStore) return
//   const g = octx
//   g.clearRect(0, 0, O_W, O_H)

//   // ë°°ê²½
//   g.fillStyle = '#0c0c0c'
//   g.fillRect(0, 0, O_W, O_H)

//   // íŒŒí˜•(ìœ„ì•„ë˜ ëŒ€ì¹­ ì±„ì›€)
//   g.beginPath()
//   const midY = Math.floor(O_H / 2)
//   g.moveTo(0, midY)
//   for (let x = 0; x < O_cols; x++) {
//     const v = waveStore[x] || 0
//     const h = Math.max(1, Math.round(v * (O_H / 2)))
//     g.lineTo(x, midY - h)
//   }
//   for (let x = O_cols - 1; x >= 0; x--) {
//     const v = waveStore[x] || 0
//     const h = Math.max(1, Math.round(v * (O_H / 2)))
//     g.lineTo(x, midY + h)
//   }
//   g.closePath()
//   g.fillStyle = '#b84cff' // ì±„ì›€(ì›í•˜ì‹œë©´ ê·¸ë¼ë°ì´ì…˜ìœ¼ë¡œ êµì²´ ê°€ëŠ¥)
//   g.fill()

//   // ì§„í–‰ ìœ„ì¹˜ ì»¤ì„œ
//   if (clipDuration > 0) {
//     const t = currentTimeSec / clipDuration
//     const cx = Math.max(0, Math.min(O_W - 1, Math.floor(t * (O_W - 1))))
//     g.fillStyle = 'rgba(255,255,255,0.8)'
//     g.fillRect(cx, 0, 2, O_H)
//   }
// }


onBeforeUnmount(() => {
  MediaUtils.disposeStream(ref_video.value?.srcObject as MediaStream);
  stopReferenceWave();
  console.log('ìŠ¤íŠ¸ë¦¼ ì •ë¦¬ ì™„ë£Œ');
});


function getRectEvenIfHidden(el: HTMLElement): DOMRect {
  const prevDisplay = el.style.display
  const wasHidden = getComputedStyle(el).display === 'none'
  if (wasHidden) { el.style.visibility = 'hidden'; el.style.display = 'block' }
  const rect = el.getBoundingClientRect()
  if (wasHidden) { el.style.display = prevDisplay; el.style.visibility = '' }
  return rect
}

/** ë…¹ìŒ ì‹œì‘ ì‹œ í˜¸ì¶œ: í”Œë ˆì´ì–´ ì˜¤ë²„ë ˆì´ ì´ˆê¸°í™” */
function initPlayerOverlay(totalSec: number) {
  // if (!ref_overviewWave.value) return
  if (!O_cols) setupOverviewCanvas()         // í­ ê³„ì‚°ì´ ì•„ì§ì´ë©´ ì„¸íŒ…
  playerTotalSec = Math.max(0.01, totalSec)
  playerStartMs = performance.now()
  playerStore = new Float32Array(O_cols)     // 0ìœ¼ë¡œ ì´ˆê¸°í™”
  ref_showPlayerOverlay.value = true
}

/** ì‹¤ì‹œê°„ RMS(0..1)ë¥¼ í˜„ì¬ ì§„í–‰ë„ì— ë§¤í•‘í•´ì„œ ëˆ„ì (í”¼í¬-í™€ë“œ) */
function accumulatePlayerOverlay(amp01: number) {
  if (!playerStore || !O_cols || playerTotalSec <= 0) return

  const elapsed = (performance.now() - playerStartMs) / 1000

  const t = Math.min(1, elapsed / playerTotalSec)

  const x = Math.max(0, Math.min(O_cols - 1, Math.floor(t * (O_cols - 1))))

  playerStore[x] = Math.max(playerStore[x], Math.max(0, Math.min(1, amp01)))

  drawOverviewAll(elapsed)   // ë§¤ í”„ë ˆì„ ë¦¬ë Œë”
}



function smoothArray(src: Float32Array, passes = 1): Float32Array {
  if (!src) return src
  let out = src
  for (let p=0; p<passes; p++){
    const next = new Float32Array(out.length)
    for (let i=0;i<out.length;i++){
      const a = out[Math.max(0, i-1)]
      const b = out[i]
      const c = out[Math.min(out.length-1, i+1)]
      next[i] = (a + 2*b + c) / 4  // ê°„ë‹¨í•œ 1D ìŠ¤ë¬´ë”©
    }
    out = next
  }
  return out
}


// ì•ˆì „ í´ë¨í”„
const clamp01 = (x:number) => Math.max(0, Math.min(1, x))
const PLAYER_DRAW_SCALE = 2.5

/** ê°œìš”(ì›ë³¸ + í”Œë ˆì´ì–´ ì˜¤ë²„ë ˆì´ + ì§„í–‰ ì»¤ì„œ) ê·¸ë¦¬ê¸° */
function drawOverviewAll(playerElapsedSec: number) {
  if (!octx) return
  const g = octx
  g.clearRect(0, 0, O_W, O_H)

  // 1) ë°°ê²½
  g.fillStyle = '#0c0c0c'
  g.fillRect(0, 0, O_W, O_H)

  const midY = Math.floor(O_H / 2)

  // 2) ì›ë³¸(ì°¸ì¡°) íŒŒí˜• ì±„ì›€ (waveStoreì— ì´ë¯¸ ì¶•ì ë¨)
  if (waveStore) {
    g.beginPath()
    g.moveTo(0, midY)
    for (let x = 0; x < O_cols; x++) {
      const v = waveStore[x] || 0
      const h = Math.max(1, Math.round(v * (O_H / 2)))
      g.lineTo(x, midY - h)
    }
    for (let x = O_cols - 1; x >= 0; x--) {
      const v = waveStore[x] || 0
      const h = Math.max(1, Math.round(v * (O_H / 2)))
      g.lineTo(x, midY + h)
    }
    g.closePath()
    g.fillStyle = '#a14cff'                // ì›ë³¸ ì˜ì—­ ì»¬ëŸ¬
    g.globalAlpha = 0.85
    g.fill()
    g.globalAlpha = 1
  }

  // 3) í”Œë ˆì´ì–´ ì˜¤ë²„ë ˆì´(ë¼ì¸)
  if (ref_showPlayerOverlay.value && playerStore) {
     const smoothed = smoothArray(playerStore, 1)
      // ëŒ€ì¹­ í´ë¦¬ê³¤ ê²½ë¡œ êµ¬ì„±
      g.beginPath()
      g.moveTo(0, midY)
      for (let x = 0; x < O_cols; x++) {
          const v = smoothed[x] || 0                  // 0..1

          const vv = clamp01(v * PLAYER_DRAW_SCALE)   // ë°°ìœ¨ ì‹œí‚¤ê¸° (ì¼ë¶€ëŸ¬ ë³´ì •í•˜ëŠ” ê±°)

          const h = Math.max(1, Math.round(vv * (O_H/2)))

          g.lineTo(x, midY - h)                       // ìœ„ìª½ ë¼ì¸
      }
      for (let x = O_cols - 1; x >= 0; x--) {
        const v = smoothed[x] || 0

        const vv = clamp01(v * PLAYER_DRAW_SCALE) // ë°°ìœ¨ ì‹œí‚¤ê¸° (ì¼ë¶€ëŸ¬ ë³´ì •í•˜ëŠ” ê±°)

        const h = Math.max(1, Math.round(vv * (O_H/2)))
        g.lineTo(x, midY + h)                       // ì•„ë˜ìª½ ë¼ì¸
      }
        g.closePath()
        // ê²¹ì¹¨ ì‹œ ì‹œì¸ì„± ì¢‹ì€ ìƒ‰ê°(ì›ë³¸ ìœ„ì— ë°˜íˆ¬ëª… í•«í•‘í¬)
        g.save()
        g.globalAlpha = 0.75
        g.fillStyle = '#ff2bbf'
        g.fill()
        g.restore()
        // í…Œë‘ë¦¬ ì–‡ê²Œ ê·¸ì–´ì£¼ë©´ ìœ¤ê³½ ë˜ë ·
        g.lineWidth = Math.max(1, Math.round((window.devicePixelRatio||1)))
        g.strokeStyle = '#ff2bbf'
        g.stroke()
  }

  // 4) ì§„í–‰ ì»¤ì„œ (í”Œë ˆì´ì–´ ê¸°ì¤€)
  if (playerTotalSec > 0 && playerElapsedSec >= 0 && playerElapsedSec <= playerTotalSec) {
      const t = Math.min(1, playerElapsedSec / playerTotalSec)
      const cx = Math.floor(t * (O_W - 1))
      g.fillStyle = 'rgba(255,255,255,0.06)'
    g.fillRect(cx, 0, O_W - cx, O_H)  // ì˜¤ë¥¸ìª½ ì˜ì—­ ì‚´ì§ í†¤ë‹¤ìš´
  }
}

//****** */íšŒì‹¬ì˜ í•„ì‚´ê¸° ëª¨í•‘ ì• ë‹ˆë©”ì´ì…˜*********/

async function morphWaveToOverview(durationMs = 600) {
  const src = ref_refWave.value as HTMLCanvasElement | null
  const dst = ref_overviewWave.value as HTMLCanvasElement | null
  const container = document.querySelector('.webrtc-container') as HTMLElement | null
  if (!src || !dst || !container) return

  // 1) ì¢Œí‘œ ê³„ì‚° (ì»¨í…Œì´ë„ˆ ê¸°ì¤€)
  const cRect = container.getBoundingClientRect()
  const sRect = src.getBoundingClientRect()
  const dRect = getRectEvenIfHidden(dst)

  const sX = sRect.left - cRect.left
  const sY = sRect.top  - cRect.top
  const dX = dRect.left - cRect.left
  const dY = dRect.top  - cRect.top

  const scaleX = dRect.width  / Math.max(1, sRect.width)
  const scaleY = dRect.height / Math.max(1, sRect.height)

  // 2) â€œìœ ë ¹ ë ˆì´ì–´â€ë¡œ ì“°ê¸° ìœ„í•´ ì‹¤ì‹œê°„ ìº”ë²„ìŠ¤ë¥¼ í´ë¡  (ì‹œê°ë§Œ ë³µì œ)
  const ghost = src.cloneNode(false) as HTMLCanvasElement
  // í˜„ì¬ ê·¸ë ¤ì§„ í”½ì…€ì„ ê·¸ëŒ€ë¡œ ë³µì‚¬(ì‹œê°ì ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ)
  // ìº”ë²„ìŠ¤ ë‚´ìš©ì„ ë³µì‚¬í•˜ë ¤ë©´ drawImageë¡œ ì°ìŠµë‹ˆë‹¤.
  ghost.width  = src.width
  ghost.height = src.height
  const gctx = ghost.getContext('2d')
  const sctx = src.getContext('2d')

  if (gctx && sctx) gctx.drawImage(src, 0, 0)

  // ì‹œì‘ ìœ„ì¹˜ì— ë°°ì¹˜
  ghost.classList.add('morph-layer')
  Object.assign(ghost.style, {
    left: `${sX}px`,
    top:  `${sY}px`,
    width:  `${sRect.width}px`,
    height: `${sRect.height}px`,
    transform: 'translate(0px,0px) scale(1,1)',
    borderRadius: getComputedStyle(src).borderRadius || '8px',
    boxShadow: '0 8px 24px rgba(0,0,0,0.35)',
  })

  // 3) DOMì— ë¶™ì´ê³  ì• ë‹ˆë©”ì´ì…˜ ì‹œì‘
  container.appendChild(ghost)

  // ì „ì²´ íŒŒí˜•ì€ ì¼ë‹¨ ìˆ¨ê¹€ â†’ ëª¨í•‘ ê±°ì˜ ëë‚  ë•Œ í˜ì´ë“œ ì¸
  const oldShow = ref_isShowOverview.value
  ref_isShowOverview.value = false
  ref_overviewVisible.value = false
  ref_isMorphing.value =true
  src.style.visibility = 'hidden'

  // ë¦¬í”Œë¡œìš° ê°•ì œ í›„ íŠ¸ëœìŠ¤í¼ ì ìš©
  void ghost.offsetWidth
  ghost.style.transitionDuration = `${durationMs}ms`
  ghost.style.transform = `translate(${dX - sX}px, ${dY - sY}px) scale(${scaleX}, ${scaleY})`
  ghost.style.borderRadius = getComputedStyle(dst).borderRadius || '8px'
  ghost.style.boxShadow = '0 12px 32px rgba(0,0,0,0.5)'

  // 4) íƒ€ì´ë°: ëë‚˜ê¸° ì‚´ì§ ì „ì— overviewë¥¼ ì¼œê³  í˜ì´ë“œì¸
  const fadeDelay = Math.max(0, durationMs - 200)
  window.setTimeout(() => {
      setupOverviewCanvas();   
    ref_isShowOverview.value = true
    // ë‹¤ìŒ í‹±ì— í˜ì´ë“œì¸ í´ë˜ìŠ¤ ì˜¨
    requestAnimationFrame(() => { ref_overviewVisible.value = true })
  }, fadeDelay)

  // 5) ì• ë‹ˆë©”ì´ì…˜ ì¢…ë£Œ ì²˜ë¦¬
  const onEnd = () => {
    ghost.removeEventListener('transitionend', onEnd)
    ghost.remove()
    ref_isMorphing.value = false
    
    // ì›ë³¸ ì‹¤ì‹œê°„ íŒŒí˜•ì€ Vueê°€ v-showë¡œ ì´ë¯¸ ìˆ¨ê²¨ë‘ (=ref_isShowOverview true)
    // í˜¹ì‹œ ëª¨í•‘ ì „ì— ë³´ì—¬ì§€ê³  ìˆì—ˆë‹¤ë©´ ì•ˆì „í•˜ê²Œ ê°€ë ¤ì£¼ê¸°
    if (!oldShow) {
      // ì‹¤ì‹œê°„ íŒŒí˜• ìˆ¨ê¹€ ìœ ì§€
    }
  }
  ghost.addEventListener('transitionend', onEnd)
}







</script>

<style scoped>
.webrtc-container {
  position: relative;
  width: 100%;
  aspect-ratio: 3/2;
  max-width:960px;
  margin:0 auto;
  overflow: hidden;
  border-radius: 8px;
  box-shadow: 0 0 20px rgba(0, 0, 0, 0.2);
    background-color: black;

      --overview-w: clamp(360px, 70%, 820px);  /* ì „ì²´ íŒŒí˜• ê°€ë¡œí­ */
  --overview-bottom: 12%;                  /* ì»¨í…Œì´ë„ˆ ë†’ì´ ëŒ€ë¹„ í•˜ë‹¨ ì—¬ë°± */
}

/* ë¹„ë””ì˜¤ëŠ” ë°”ë‹¥ì— ìœ„ì¹˜ */
.webrtc-video {
  width: 100%;
  height: 100%;
  object-fit: cover;
  display: block;
}

/* ë Œë”ë§ ìº”ë²„ìŠ¤ëŠ” ë¹„ë””ì˜¤ ìœ„ì— */
.overlay-canvas {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  pointer-events: none;
}

/* UI ì˜¤ë²„ë ˆì´ */
.ui-overlay {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  padding: 16px;
  display: flex;
  flex-direction: column;
  justify-content: space-between;
  pointer-events: none; /* UI ë²„íŠ¼ì€ pointer-eventsë¥¼ ì¼œì•¼ í•¨ */
  z-index: 2;
}

.top-bar {
  display: flex;
  justify-content: space-between;
  color: white;
  font-weight: bold;
  font-size: 20px;
}

.button-bar {
  margin-top: auto;
  display: flex;
  gap: 12px;
  justify-content: center;
  pointer-events: auto;
}

button {
  background: rgba(255, 255, 255, 0.1);
  color: white;
  border: 1px solid white;
  border-radius: 8px;
  padding: 8px 16px;
  cursor: pointer;
  backdrop-filter: blur(4px);
  transition: background 0.3s;
}
button:hover {
  background: rgba(255, 255, 255, 0.3);
}

.recorded-preview {
  position: absolute;
  right: 12px;
  bottom: 12px;
  width: 320px;           /* í•„ìš” ì‹œ í¬ê¸° ì¡°ì ˆ */
  aspect-ratio: 16 / 9;
  background: #000;
  border: 1px solid rgba(255,255,255,0.3);
  border-radius: 8px;
  box-shadow: 0 8px 24px rgba(0,0,0,0.35);
  z-index: 3;             /* .ui-overlay(2)ì™€ ìº”ë²„ìŠ¤ë³´ë‹¤ ìœ„ */
  pointer-events: auto;   /* ì»¨íŠ¸ë¡¤ í´ë¦­ ê°€ëŠ¥ */
}


.download-link{
  color: white;
  text-decoration: none;
  border: 1px solid white;
  border-radius: 8px;
  padding: 8px 16px;
  backdrop-filter: blur(4px);
  transition: background 0.3s;
}
.download-link:hover{
  background: rgba(255, 255, 255, 0.3);
}


.countdown-overlay {
  position: absolute;
  inset: 0;
  display: grid;
  place-items: center;
  font-size: clamp(48px, 8vw, 120px);
  font-weight: 800;
  color: #fff;
  text-shadow: 0 6px 24px rgba(0,0,0,0.45);
  z-index: 3;
  pointer-events: none;
}

/* ì°¸ì¡° ì˜ìƒ ì˜¤ë²„ë ˆì´ */
.refclip-overlay {
  position: absolute;
  inset: 0;
  background: rgba(0,0,0,0.75);
  display: grid;
  place-items: center;
  z-index: 2;
}

.refclip-video {
  width: 0;
  height : 0;
  background: #000;
  border-radius: 12px;
  box-shadow: 0 12px 32px rgba(0,0,0,0.5);
}

.refclip-img {
  width: min(90vw, 960px);
  aspect-ratio: 16 / 9;
  background: #000;
  opacity: 0.5;
  border-radius: 12px;
  box-shadow: 0 12px 32px rgba(0,0,0,0.5);
}

.bars-container {
  display: flex;
  align-items: flex-end;
  gap: 4px;
  height: 40px; /* ë§‰ëŒ€ ìµœëŒ€ ë†’ì´ */
  width: 120px;
}
.bar {
  flex: 1;
  background: linear-gradient(to top, #4ade80, #facc15, #f87171);
  transition: height 0.08s ease-out;
}

.ref-wave{
  position:absolute;
  left:16px; right:16px; bottom:16px;
  height:96px;
  background:#000;
  border-radius:8px;
  z-index: 3;          /* <- ì¶”ê°€ */
  pointer-events: none;/* UI í´ë¦­ ë°©í•´ ë°©ì§€(ì„ íƒ) */
}

.ref-overview{
  position:absolute;
  left:50%;
  transform: translateX(-50%);
  bottom: var(--overview-bottom);
  width: var(--overview-w);
  height:72px;

  background:#0c0c0c;
  border-radius:8px;
  z-index: 5;
  pointer-events: none;
  box-shadow: inset 0 0 0 1px rgba(255,255,255,0.06);
  opacity: 0;
  transition: opacity 320ms ease;
}

/* ëª¨í•‘ì— ì“¸ ê³µí†µ ë ˆì´ì–´ ìŠ¤íƒ€ì¼ */
.morph-layer {
  position: absolute;        /* ì»¨í…Œì´ë„ˆ ê¸°ì¤€ìœ¼ë¡œ ì´ë™ */
  transform-origin: top left;
  will-change: transform, border-radius, box-shadow, opacity;
  z-index: 7;                /* ë§¨ ìœ„ë¡œ ë„ì›Œì„œ ìì—°ìŠ¤ëŸ½ê²Œ */
  /* ì•„ë˜ íŠ¸ëœì§€ì…˜ì€ JSì—ì„œ durationë§Œ ë°”ê¿”ë„ ë¨ */
  transition:
    transform 600ms cubic-bezier(.22,.61,.36,1),
    border-radius 600ms cubic-bezier(.22,.61,.36,1),
    box-shadow 600ms cubic-bezier(.22,.61,.36,1),
    opacity 300ms ease;
}


/* ì „ì²´ íŒŒí˜• í˜ì´ë“œ ì¸ */
.ref-overview {
  opacity: 0;
  transition: opacity 320ms ease;
}
.ref-overview.fade-in {
  opacity: 1;
}

/* ëª¨í•‘ ë™ì•ˆ ì›ë³¸ íŒŒí˜•ì€ ì•ˆ ë³´ì´ê²Œ */
.ref-wave.is-morphing {
  opacity: 0;                 /* ì‹œê°ì ìœ¼ë¡œ ì™„ì „ ìˆ¨ê¹€ */
  visibility: hidden;         /* Safari ì”ìƒ ë°©ì§€ */
  pointer-events: none;
}


</style>
